{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "respective-testimony",
   "metadata": {},
   "source": [
    "## Comparing grounded theory and topic modeling\n",
    "### Baumer et al"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-arrest",
   "metadata": {},
   "source": [
    "Method 1: Grounded theory\n",
    "\n",
    "Method 2: Topic Modeling: Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-survivor",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/bsherin/text_mining_content/main/baumertable1.png\" width=\"700px\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-qatar",
   "metadata": {},
   "source": [
    "## Computational  Grounded Theory:  A Methodological  Framework \n",
    "\n",
    "### Laura K. Nelson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-roberts",
   "metadata": {},
   "source": [
    "### Step 1: Pattern Detection Using Human-centered Computational  Exploratory Analysis \n",
    "Combination of difference of proportions (a lexical selection technique) and STM (a\n",
    "structural topic modeling algorithm)\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/bsherin/text_mining_content/main/nelsontable3.png\" width=\"700px\">\n",
    "\n",
    "### Step 2: Hypothesis Refinement Using Human-centered Interpretation \n",
    "Computational guided deep reading\n",
    "\n",
    "### Step 3: Pattern Confirmation \n",
    "\n",
    "Wordnet (for specificity) and an online dictionary (for concreteness)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-scope",
   "metadata": {},
   "source": [
    "## Combining Machine Learning and Qualitative Methods to Elaborate  Students’ Ideas About the Generality of their Model-Based  Explanations  \n",
    "### Rosenberg and Krist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-jaguar",
   "metadata": {},
   "source": [
    "* Start with clustering responses as a kind of topic modeling (similar to Bruce's 2013 paper)\n",
    "* Used this to revise a coding scheme/construct map\n",
    "* Attempted to apply the new scheme\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-damage",
   "metadata": {},
   "source": [
    "## Introduction to latent Dirichlet allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-leeds",
   "metadata": {},
   "source": [
    "LDA is a kind of topic modeling.\n",
    "\n",
    "It is based in a *generative model*. The idea is that we imagine that our data corpus was generated by a very particular kind of machine.\n",
    "\n",
    "* The machine has a set of \"topics.\" Each topic is like a little machine that produces words with a different probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-advance",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/bsherin/text_mining_content/main/topics.png\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-martin",
   "metadata": {},
   "source": [
    "* Each topic has a some base probability of being used.\n",
    "\n",
    "* In each document, there is a different weighting for each topic.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/bsherin/text_mining_content/main/generative.png\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-injury",
   "metadata": {},
   "source": [
    "#### The parameters that describe the model:\n",
    "* The number of topics.\n",
    "* A base level probability associated with each topic.\n",
    "* For each topic, the probability of producing each word in the vocabulary.\n",
    "* For each document, a weighting for each topic.\n",
    "\n",
    "Latent Dirichlet Allocation does this! (Blei, Ng, & Jordan, 2003). \n",
    "\n",
    "Tries to find the parameters that maximize probability that the particular data corpus would be observed\n",
    "\n",
    "But:\n",
    "* We still have to specify the number of topics, plus a number of parameters that govern how the algorithm operates.\n",
    "* The algorithm isn’t deterministic. It gives different answers each time it’s run.\n",
    "* There isn’t a simple way to judge the quality of a fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-disease",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
