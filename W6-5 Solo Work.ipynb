{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solo work for week 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paragraph-paragraph similarity as a measure of text difficulty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our task here is to develop a measure of how difficult a text is by looking at the inter-paragraph cohesion. \n",
    "The idea is that we'll:\n",
    "\n",
    "* construct a normalized vector for every sentence or paragraph in a text. \n",
    "* find the similarity between sequential pair of paragraphs\n",
    "* and, finally, we'll find the averages of these similarities.\n",
    "\n",
    "If the average of the similarities is high (i.e., closer to one) then the cohesion is high.\n",
    "\n",
    "I'm thinking that you'll pick a couple of texts from the Gutenberg corpus, and compare their cohesions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Note:\n",
    ">\n",
    "> I'm not going to give you much scaffolding here. \n",
    "> If you're stuck, let me know, and I'll post a more scaffolded version later in the week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step will be to read in one of these corpora. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "mycorpus = nltk.corpus.PlaintextCorpusReader(\"corpora/gutenberg\", 'melville-moby_dick.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read this in using a special corpus reader that comes with nltk. When the data is read in this way,you can access the book as paragraphs or sentences. For example, this gives you the paragraphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']']], [['ETYMOLOGY', '.']], ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycorpus.paras()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `mycorpus.paras()` give you a list, where each item in the list is a paragraph. \n",
    "But each paragraph is itself a list of sentences.\n",
    "\n",
    "Probably a first step then is to combine the sentences in each paragraph into one long list of words.\n",
    "I guess I'll do that for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = []\n",
    "for para in mycorpus.paras():\n",
    "    flat_para = []\n",
    "    for sent in para:\n",
    "        flat_para += sent\n",
    "    paragraphs.append(flat_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `paragraphs` is a long list of paragraphs, with each paragraph being a list of words.\n",
    "The next step is to convert each of these paragraphs into a normalized vector.\n",
    "\n",
    "(You'll have to first construct a vocabulary. You'll also want to read in a stop list and remove stop words at some point in your process.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next find the dot product between each successive pair of paragraphs.\n",
    "Add them up.\n",
    "Then divide by the total number of paragraphs.\n",
    "\n",
    "That's your measure of coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply your measure to some of the other Gutenberg books I've provided, or others you find online.\n",
    "\n",
    "You can also play with your measure to see if you can improve it. Some possibilities are to change the number of words in your vocabular or use a different weighting factor in constructing your document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
