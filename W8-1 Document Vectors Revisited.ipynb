{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aerial-referral",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction: Working up to Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-multiple",
   "metadata": {},
   "source": [
    "Today we are going to review a bit, and build up a bit more slowly to *word vectors.* \n",
    "\n",
    "This is important because it will put us in a position to understand some of the more recent developments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-garden",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some preliminaries\n",
    "\n",
    "First some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-transportation",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A few useful functions for dealing with vectors and matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_vec(v):\n",
    "    mag = np.linalg.norm(v)\n",
    "    if mag == 0:\n",
    "        return v\n",
    "    return v / np.linalg.norm(v)\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def normalize_rows(x):\n",
    "    return normalize(x, axis=1)\n",
    "\n",
    "def normalize_columns(x):\n",
    "    return normalize(x, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-campbell",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally some functions that are for displaying things nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_float(potential_float):\n",
    "    try:\n",
    "        float(potential_float)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def round_if_float(v, prec=3):\n",
    "    if check_float(v):\n",
    "        return round(float(v), prec)\n",
    "    return v\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "def list_table(the_list, color_nums=False):\n",
    "    html = [\"<table style= 'border: 1px solid black; display:inline-block'>\"]\n",
    "    for row in the_list:\n",
    "        html.append(\"<tr>\")\n",
    "        for col in row:\n",
    "            if color_nums and check_float(col) and not float(col) == 0:\n",
    "                html.append(\"<td align='left' style='border: .5px solid gray; color: {1}; font-weight: bold'>{0}</td>\".format(round_if_float(col), color_nums))\n",
    "            else:\n",
    "                html.append(\"<td align='left' style='border: .5px solid gray;'>{0}</td>\".format(round_if_float(col)))\n",
    "        html.append(\"</tr>\")\n",
    "    html.append(\"</table>\")\n",
    "    return display(HTML(''.join(html)))\n",
    "\n",
    "def show_labeled_table(mat, col_names=None, row_names=None, nrows=10, ncols=10, color_nums=\"red\"):\n",
    "    sml = mat[:nrows, :ncols]\n",
    "    if col_names is not None:\n",
    "        sml = np.vstack([col_names[:ncols], sml])\n",
    "    if row_names is not None:\n",
    "        rnames = [[p] for p in row_names[:nrows]]\n",
    "        if col_names is not None:\n",
    "            new_col = np.array([[\"_\"]] + rnames)\n",
    "        else:\n",
    "            new_col = np.array(rnames)\n",
    "        sml = np.hstack((new_col, sml))\n",
    "    return list_table(sml, color_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-surfing",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Document vectors, once more\n",
    "\n",
    "To keep things simple, we are going to make a small number of short documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "institutional-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_transcript_docs = {\n",
    "    \"d1\": \"That's because of the sun is in the center and the Earth moves around the sun and the Earth is like at one point in the winter\", \n",
    "    \"d2\": \"it's like farther away from the sun and towards the summer it's closer it's near, towards the sun.\",\n",
    "    \"d3\": \"The sun's in the middle  and the Earth kind of orbits around it.\",\n",
    "    \"d4\": \"And like say at one - it's probably more of an ovally type thing  In the winter, er probably this will be winter since it's further away\",\n",
    "    \"d5\": \"that's winter would be like, the Earth orbits around the sun .  Like summer is the closest to the sun\", \n",
    "    \"d6\": \"Spring is kind of a little further away, and then like Fall  is further away then spring but not as far as winter, and then winter is the furthest.\",\n",
    "    \"d7\": \"the sun doesn't, like the flashlight and the bulb, it hits summer, the lines like fade in , they get there closer, like quicker\",\n",
    "    \"d8\": \"And by the time they get there [winter], it fades and it's a lot colder for winter\"\n",
    "}\n",
    "\n",
    "transcript_doc_names = list(raw_transcript_docs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-spanish",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We'll load my tokenizer and stop list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-polymer",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from seasons_module import seasons_tokenize\n",
    "\n",
    "f = open(\"lists/seasons_stop_list.txt\")\n",
    "stop_list = set(f.read().split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-injection",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We tokenize these short documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-blackjack",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_transcript_docs = [seasons_tokenize(doc) for doc in raw_transcript_docs.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-herald",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Next we make a vocabulary by finding the 10 most common words in these short documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-harvard",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist()\n",
    "for doc in tokenized_transcript_docs:\n",
    "    fdist.update(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-spread",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for tup in fdist.most_common(100):\n",
    "    if tup[0] not in stop_list:\n",
    "        vocab.append(tup[0])\n",
    "vocab = vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-tender",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-halloween",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, we compute the document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_doc_vector(tdoc, vocab):\n",
    "    return np.array([tdoc.count(w) for w in vocab])\n",
    "\n",
    "\n",
    "transcript_doc_vectors = []\n",
    "for tdoc in tokenized_transcript_docs:\n",
    "    transcript_doc_vectors.append(compute_doc_vector(tdoc, vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-edward",
   "metadata": {},
   "source": [
    "Heres' what one of these document vectors looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_doc_vectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-legislation",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It will often be convenient to take a bunch of these document vectors and put them into a big table.\n",
    "\n",
    "Here's what that looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_dt_matrix = np.array(transcript_doc_vectors)\n",
    "\n",
    "show_labeled_table(transcript_dt_matrix, vocab, transcript_doc_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-reader",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this case, each of the rows corresponds to one of our documents, and each column corresponds to one of the terms in our vocabulary.\n",
    "\n",
    "We'll call this a document-by-term matrix.\n",
    "\n",
    "To compare two documents we can pick out the corresponding rows, then find normalize them and find their dot products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_doc_vectors(docA, docB, dnames, dt_matrix):\n",
    "    v1 = dt_matrix[dnames.index(docA)]\n",
    "    v2 = dt_matrix[dnames.index(docB)]\n",
    "    return np.dot(norm_vec(v1), norm_vec(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-ticket",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compare_doc_vectors(\"d1\", \"d3\", transcript_doc_names, transcript_dt_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-header",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Sometimes we'll want to flip or \"transpose\" our document-by-term matrix so that so that the terms are the rows and the columns are the documents. This is a term-by-document matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-glance",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "transcript_td_matrix = transcript_dt_matrix.transpose()\n",
    "\n",
    "show_labeled_table(transcript_td_matrix, transcript_doc_names, vocab)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "316.59375px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
